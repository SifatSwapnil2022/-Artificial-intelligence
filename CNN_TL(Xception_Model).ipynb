{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnpLvwty7nm7"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "ZsP9NSHQ8bRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ],
      "metadata": {
        "id": "xmJVVrvX8bIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/drive/MyDrive/Artificial Intelligence part_1/Train'\n",
        "test_dir = '/content/drive/MyDrive/Artificial Intelligence part_1/Test'\n",
        "val_dir = '/content/drive/MyDrive/Artificial Intelligence part_1/Validation'\n"
      ],
      "metadata": {
        "id": "Tqqyfp-OHBRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Validation and test data generator (only rescaling)\n",
        "val_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "# Flow from directories\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n"
      ],
      "metadata": {
        "id": "HrdKI3teHJKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    # Convolutional Layers\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Flatten and Fully Connected Layers\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "UDn0YqEEnZI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=10,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=len(val_generator)\n",
        ")\n"
      ],
      "metadata": {
        "id": "4kR4jJVKneTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on test data\n",
        "test_loss, test_acc = model.evaluate(test_generator, steps=len(test_generator))\n",
        "print(f\"Test Accuracy: {test_acc:.2f}\")\n"
      ],
      "metadata": {
        "id": "V4Bs3Mw7nixS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YKGWjaY9rDC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unseen data\n",
        "\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Load a single image\n",
        "img_path = '/content/drive/MyDrive/Artificial Intelligence part_1/images.jfif'  # Update path\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# Predict\n",
        "prediction = model.predict(img_array)\n",
        "if prediction[0] > 0.5:\n",
        "    print(\"Fake\")\n",
        "else:\n",
        "    print(\"Real\")\n"
      ],
      "metadata": {
        "id": "KWQ2X8ACrIhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MwT_RyzUrjVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transfer learning using the Xception model"
      ],
      "metadata": {
        "id": "E_aT0nP40Tc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "###############################         Data processing        #############################\n",
        "\n",
        "# Data generators with augmentation for training and rescaling for test/validation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "# Load data from directories\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "\n",
        "###################      Build  Xception model   ##################\n",
        "\n",
        "\n",
        "# Load pre-trained Xception model without the top layers\n",
        "base_model = Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Add custom layers\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Freeze the base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#################################     Train the model\n",
        "\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=10,  # Adjust based on your needs\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=len(val_generator)\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "#################### Evaluate ####################\n",
        "# Evaluate on test data\n",
        "test_loss, test_acc = model.evaluate(test_generator, steps=len(test_generator))\n",
        "print(f\"Test Accuracy: {test_acc:.2f}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QzgnRaaP0VUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "44IFvggZ1NLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Z6iCVEaB1N9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Load and preprocess a single image\n",
        "img_path = '/content/drive/MyDrive/Artificial Intelligence part_1/Test/Real/real_1001.jpg'  # Update path\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# Predict\n",
        "prediction = model.predict(img_array)\n",
        "if prediction[0] > 0.5:\n",
        "    print(\"Fake\")\n",
        "else:\n",
        "    print(\"Real\")\n"
      ],
      "metadata": {
        "id": "E_jqo8TI1SAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers[-20:]:  # Unfreeze the last 20 layers\n",
        "    layer.trainable = True\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Retrain with a lower learning rate\n",
        "fine_tune_history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=5,  # Few epochs for fine-tuning\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=len(val_generator)\n",
        ")\n"
      ],
      "metadata": {
        "id": "ZwJs4i1H1UtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "# Generate predictions\n",
        "y_true = test_generator.classes\n",
        "y_pred = model.predict(test_generator)\n",
        "y_pred_classes = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true, y_pred_classes)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Classification Report\n",
        "print(classification_report(y_true, y_pred_classes, target_names=['Real', 'Fake']))\n"
      ],
      "metadata": {
        "id": "d-jK__Yd1XTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NxBwSc3efLbB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#                                       **GAN** MODEL"
      ],
      "metadata": {
        "id": "-YDR56bYuhdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, Flatten, Dense, Reshape\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "BaIjlLaeujgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize and augment the dataset\n",
        "datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_generator = datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "PD63s0n5umn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator():\n",
        "    model = Sequential([\n",
        "        Dense(8*8*256, activation='relu', input_dim=100),\n",
        "        Reshape((8, 8, 256)),\n",
        "        Conv2DTranspose(128, kernel_size=4, strides=2, padding='same', activation='relu'),\n",
        "        Conv2DTranspose(64, kernel_size=4, strides=2, padding='same', activation='relu'),\n",
        "        Conv2DTranspose(3, kernel_size=4, strides=2, padding='same', activation='sigmoid')  # Output: 64x64x3\n",
        "    ])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "g_L55abhuo2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_discriminator(input_shape=(64, 64, 3)):\n",
        "    model = Sequential([\n",
        "        Conv2D(64, kernel_size=4, strides=2, padding='same', input_shape=input_shape, activation='relu'),\n",
        "        Conv2D(128, kernel_size=4, strides=2, padding='same', activation='relu'),\n",
        "        Conv2D(256, kernel_size=4, strides=2, padding='same', activation='relu'),\n",
        "        Flatten(),\n",
        "        Dense(1, activation='sigmoid')  # Binary classification: Real or Fake\n",
        "    ])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "_h_acar6uqO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_gan(generator, discriminator):\n",
        "    discriminator.trainable = False\n",
        "    gan_input = Input(shape=(100,))\n",
        "    fake_image = generator(gan_input)\n",
        "    validity = discriminator(fake_image)\n",
        "    return Model(gan_input, validity)\n"
      ],
      "metadata": {
        "id": "UaA0-TcNuuaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize models\n",
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n",
        "gan = build_gan(generator, discriminator)\n",
        "\n",
        "# Compile models\n",
        "discriminator.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "gan.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy')\n"
      ],
      "metadata": {
        "id": "dHqzsdt7uxur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "epochs = 700\n",
        "batch_size = 32\n",
        "latent_dim = 100\n",
        "\n",
        "real_label = np.ones((batch_size, 1))  # Labels for real images\n",
        "fake_label = np.zeros((batch_size, 1))  # Labels for fake images\n",
        "\n",
        "# Training process\n",
        "for epoch in range(epochs):\n",
        "    # Train Discriminator\n",
        "    real_images = next(train_generator)[0]  # Get a batch of real images\n",
        "    z = np.random.normal(0, 1, (batch_size, latent_dim))  # Generate random noise\n",
        "    fake_images = generator.predict(z)  # Generate fake images\n",
        "\n",
        "    d_loss_real = discriminator.train_on_batch(real_images, real_label)\n",
        "    d_loss_fake = discriminator.train_on_batch(fake_images, fake_label)\n",
        "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "    # Train Generator\n",
        "    z = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "    g_loss = gan.train_on_batch(z, real_label)\n",
        "\n",
        "    # Print progress\n",
        "    if epoch % 50 == 0:\n",
        "        print(f\"Epoch {epoch} - D Loss: {d_loss[0]}, G Loss: {g_loss}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "IvXYGXLY8gge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_images, real_labels = next(test_generator)\n",
        "z = np.random.normal(0, 1, (len(real_images), latent_dim))\n",
        "fake_images = generator.predict(z)\n",
        "\n",
        "# Evaluate real and fake images using the discriminator\n",
        "real_preds = discriminator.predict(real_images)\n",
        "fake_preds = discriminator.predict(fake_images)\n"
      ],
      "metadata": {
        "id": "UL4iukNku586"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = np.concatenate([np.ones(len(real_preds)), np.zeros(len(fake_preds))])\n",
        "y_pred = np.concatenate([real_preds, fake_preds])\n",
        "y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred_binary)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Fake', 'Real'], yticklabels=['Fake', 'Real'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8pjyGX--vBfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true, y_pred_binary, target_names=['Fake', 'Real']))\n"
      ],
      "metadata": {
        "id": "rnL7a2zLvCPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot real images\n",
        "plt.figure(figsize=(10, 5))\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    plt.imshow(real_images[i])\n",
        "    plt.title(\"Real\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Plot fake images\n",
        "plt.figure(figsize=(10, 5))\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    plt.imshow(fake_images[i])\n",
        "    plt.title(\"Fake\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Waq2uMx6vDq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(d_loss, label='Discriminator Loss')\n",
        "plt.plot(g_loss, label='Generator Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training Loss Curves')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "p87_bt3fvGKX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}